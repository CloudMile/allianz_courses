{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# r = requests.get('https://storage.googleapis.com/allianz-course/libs/utils.py', verify=False)\n",
    "# with tf.gfile.Open('./utils.py', 'wb') as w:\n",
    "#     w.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf\n",
    "import seaborn as sns, keras\n",
    "sns.set(style='white')\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, Activation, Input, Dropout, Embedding, Flatten, Input\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import regularizers\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('https://storage.googleapis.com/allianz-course/data/ratings.csv')\n",
    "movies = pd.read_csv('https://storage.googleapis.com/allianz-course/data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ratings.rating.describe(), '\\n')\n",
    "print(ratings.rating.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "* rating的分數介於 0.5 ~ 5分, 最小差距為0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit user id and movie id\n",
    "uid_enc, mid_enc = LabelEncoder(), LabelEncoder()\n",
    "uid_enc.fit(ratings.userId)\n",
    "mid_enc.fit(movies.movieId)\n",
    "\n",
    "# Encode user id and movie id to indexed real value\n",
    "ratings[\"userId\"] = uid_enc.transform(ratings.userId)\n",
    "ratings[\"movieId\"] = mid_enc.transform(ratings.movieId)\n",
    "movies[\"movieId\"] = mid_enc.transform(movies.movieId)\n",
    "\n",
    "# Dictionary of movie id and title\n",
    "mid_map = pd.Series(dict(zip(movies.movieId, movies.title)))\n",
    "\n",
    "# Number of users, number of movies\n",
    "n_users, n_movies = len(uid_enc.classes_), len(mid_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_movies(movies):\n",
    "    movies = movies.reset_index(drop=True)\n",
    "    # movies.loc[movies.genres == \"(no genres listed)\", \"genres\"] = \"\"\n",
    "    movies[\"genres\"] = movies.genres.str.split(\"\\|\")\n",
    "    genres_cnt = Counter()\n",
    "    movies.genres.map(genres_cnt.update)\n",
    "    \n",
    "    genres_map = LabelEncoder()\n",
    "    genres_map.fit( np.array(genres_cnt.most_common())[:, 0] )\n",
    "    movies[\"genres\"] = movies.genres.map(lambda lst: genres_map.transform(lst))\n",
    "    return movies, genres_map\n",
    "\n",
    "movies_encoded, genres_map = do_movies(movies)\n",
    "movies_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train, Test Data\n",
    "* 以4分為閥值, 4分以上為positive, 未滿4分為negative\n",
    "* 每個user分positive, negative兩部分, 各取30%到valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ratings(data, pos_thres=4, test_ratio=0.3):\n",
    "    \"\"\"依照test_ratio切割movielens train test資料\"\"\"\n",
    "    tr, te = [], []\n",
    "    for u, df in data.groupby(\"userId\"):\n",
    "        if len(df) < 5: continue\n",
    "\n",
    "        pos, neg = df.query(\"rating >= {}\".format(pos_thres)), df.query(\"rating < {}\".format(pos_thres))\n",
    "        # Split positive part\n",
    "        pos_len = int(len(pos) * (1 - test_ratio))\n",
    "        tr_pos = pos[:pos_len]\n",
    "        te_pos = pos[pos_len:]\n",
    "        # Split negative part\n",
    "        neg_len = int(len(neg) * (1 - test_ratio))\n",
    "        tr_neg = neg[:neg_len]\n",
    "        te_neg = neg[neg_len:]\n",
    "\n",
    "        tr.append(tr_pos.append(tr_neg))\n",
    "        te.append(te_pos.append(te_neg))\n",
    "    return pd.concat(tr, ignore_index=True), pd.concat(te, ignore_index=True)\n",
    "\n",
    "tr, te = split_ratings(ratings, 4, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Rating Matrix (Interaction Between Users and Movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_rating_mat = np.zeros((n_users, n_movies))\n",
    "# Valid data rating matrix\n",
    "te_rating_mat = np.zeros((n_users, n_movies))\n",
    "\n",
    "# Train rating matrix\n",
    "for idx, r in tr.iterrows():\n",
    "    tr_rating_mat[int(r.userId), int(r.movieId)] = r.rating\n",
    "# Valid rating matrix    \n",
    "for idx, r in te.iterrows():\n",
    "    te_rating_mat[int(r.userId), int(r.movieId)] = r.rating\n",
    "    \n",
    "print('Shape of train interaction matrix: ', tr_rating_mat.shape)\n",
    "print(tr_rating_mat, '\\n')\n",
    "print('Shape of test interaction matrix: ', te_rating_mat.shape)\n",
    "print(te_rating_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( tr.head() )\n",
    "print()\n",
    "print( te.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model of Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import dot, add, Layer\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adagrad, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(n_users, n_movies, emb_size, reg):\n",
    "    # Input tesors\n",
    "    inp_user = Input([1], dtype='int32')\n",
    "    inp_movie = Input([1], dtype='int32')\n",
    "    # Hack: only input integer => \"0\"\n",
    "    inp_global = Input([1], dtype='int32')\n",
    "    \n",
    "    # User, movie embedding\n",
    "    emb_user = Embedding(n_users, emb_size, embeddings_initializer='glorot_uniform',\n",
    "                         embeddings_regularizer=regularizers.l2(reg), name='emb_user')(inp_user)\n",
    "    emb_movie = Embedding(n_movies, emb_size, embeddings_initializer='glorot_uniform',\n",
    "                         embeddings_regularizer=regularizers.l2(reg), name='emb_movie')(inp_movie)\n",
    "    emb_user = Flatten()(emb_user)\n",
    "    emb_movie = Flatten()(emb_movie)\n",
    "    \n",
    "    # Bias terms\n",
    "    b_user = Flatten()(Embedding(n_users, 1, \n",
    "                                 embeddings_initializer='glorot_uniform', \n",
    "                                 name='b_user')(inp_user))\n",
    "    b_movie = Flatten()(Embedding(n_movies, 1, \n",
    "                                  embeddings_initializer='glorot_uniform', \n",
    "                                  name='b_movie')(inp_movie))\n",
    "    b_global = Flatten()(Embedding(1, 1, \n",
    "                                   embeddings_initializer='glorot_uniform', \n",
    "                                   name='b_global')(inp_global))\n",
    "    # Implements the formulation\n",
    "    nets = dot([emb_user, emb_movie], axes=1)\n",
    "    nets = add([nets, b_user, b_movie, b_global])\n",
    "    \n",
    "    # Input: [user, movie, zero]\n",
    "    model = Model([inp_user, inp_movie, inp_global], nets)\n",
    "    model.summary()\n",
    "    return model, Model(inp_movie, emb_movie)\n",
    "\n",
    "emb_size = 16\n",
    "reg = 0.0005\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "K.clear_session()\n",
    "model_mf, _ = get_model(n_users, n_movies, emb_size, reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = [tr.userId[:, None], \n",
    "        tr.movieId[:, None], \n",
    "        np.zeros([len(tr), 1])]\n",
    "tr_y = tr.rating[:, None]\n",
    "# -----------------------------------------------------------------------\n",
    "te_x = [te.userId[:, None], \n",
    "        te.movieId[:, None], \n",
    "        np.zeros([len(te), 1])]\n",
    "te_y = te.rating[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Callback Function\n",
    "* keras.callbacks.ModelCheckpoint: 只存檔最好的結果, 是另一種防止overfitting的方式\n",
    "    * save_best_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_mf.compile(optimizer=Adagrad(lr=0.1), loss='mse')\n",
    "\n",
    "model_dir = \"./model_mf\"\n",
    "hist = model_mf.fit(x=tr_x,\n",
    "                    y=tr_y,\n",
    "                    validation_data=(te_x, te_y),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[ModelCheckpoint(filepath=model_dir, \n",
    "                                               save_weights_only=True, \n",
    "                                               save_best_only=True)])\n",
    "\n",
    "# After training, load the best weights back\n",
    "model_mf.load_weights(model_dir)\n",
    "\n",
    "sns.lineplot(np.arange(len(hist.history['loss'])), hist.history['loss'], label='train')\n",
    "sns.lineplot(np.arange(len(hist.history['val_loss'])), hist.history['val_loss'], label='test')\n",
    "plt.title('loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_mf.predict(te_x).ravel()\n",
    "print('Shape of test data: ', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "* 定義4分以上為正向評價, 4分以下為負向評價"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: \", np.sqrt(np.mean((pred - te_y.ravel())**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc_curve(y, pred_proba):\n",
    "    fpr, tpr, _ = roc_curve(y, pred_proba, pos_label=1)\n",
    "    auc_scr = auc(fpr, tpr)\n",
    "    print(\"auc:\", auc_scr)\n",
    "    f, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.plot(fpr, tpr, label='ROC CURVE')\n",
    "    ax.set_xlabel('False positive rate')\n",
    "    ax.set_ylabel('True positive rate')\n",
    "    ax.set_title('Area Under Curve(ROC) (score: {:.4f})'.format(auc_scr))\n",
    "    ax.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "draw_roc_curve(te.rating >= 4, pred / pred.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single User Rating Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user id from 0 ~ 670\n",
    "uid = 22\n",
    "tmp = te.query(f\"userId == {uid}\")\n",
    "single_pred = model_mf.predict(\n",
    "    [np.repeat(uid, len(tmp.movieId))[:, None],\n",
    "     tmp.movieId[:, None],\n",
    "     np.zeros([len(tmp.movieId), 1])]).ravel()\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_title(\"pred distribute\")\n",
    "sns.distplot(single_pred, ax=ax[0])\n",
    "ax[1].set_title(\"real distribute\")\n",
    "sns.distplot(te.query(f\"userId == '{uid}'\").rating, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single User Detail Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# user id from 0 ~ 670\n",
    "uid = 22\n",
    "tmp = te.query(f\"userId == {uid}\")\n",
    "single_pred = model_mf.predict(\n",
    "    [np.repeat(uid, len(tmp.movieId))[:, None],\n",
    "     tmp.movieId[:, None],\n",
    "     np.zeros([len(tmp.movieId), 1])]).ravel()\n",
    "\n",
    "recommDf = pd.DataFrame(data={\n",
    "              \"userId\": uid,\n",
    "              \"movieId\": tmp.movieId,\n",
    "              \"title\": mid_map[tmp.movieId].values,\n",
    "              \"rating\": tmp.rating.values,\n",
    "              \"predRating\": single_pred},\n",
    "             columns=(\"userId\", \"movieId\", \"title\", \"rating\", \"predRating\"))\n",
    "# ascending 可以調整True or False觀察結果\n",
    "recommDf.sort_values(\"rating\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recommDf.sort_values(\"predRating\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision@K (K = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Computing Precision@K, See the Count Plot Below First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ary, neg_ary = [], []\n",
    "for label in te_rating_mat:\n",
    "    label = label[label != 0]\n",
    "    pos_ary.append(sum(label >= 4))\n",
    "    neg_ary.append(sum(label < 4))\n",
    "    \n",
    "def draw_pos_neg(idx):\n",
    "    pd.DataFrame(\n",
    "        index=idx,\n",
    "        data={\"pos\": np.array(pos_ary)[idx], \"neg\": np.array(neg_ary)[idx]}).plot.bar(figsize=(10, 5), alpha=0.8)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "draw_pos_neg(np.arange(len(te_rating_mat))[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "1. 0號, 2號, 5號, 9號 user 正向評價數量 < 10, 就算model全部預測命中, 命中率也不會是 100%!\n",
    "    ex: 0號user只有1個正向評價, 全部命中也只得到0.1的分數\n",
    "2. 3號user正向評價是負向評價的5倍多, 就算亂猜, 中的機率也很高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_condition(label):\n",
    "    label = label[label != 0]\n",
    "    pos, neg = sum(label >= 4), sum(label < 4)\n",
    "    return len(label) >= 10 and pos <= neg and pos > 0\n",
    "\n",
    "def norm_condition(label):\n",
    "    label = label[label != 0]\n",
    "    return sum(label >= 4) > 0 and sum(label < 4) > 0\n",
    "\n",
    "_ = sum(np.sum(te_rating_mat >= 4, 1) < 10)\n",
    "print(\"{} 個user正向評價總數小於10!\".format(_))\n",
    "print(\"rating數量 >= 10 且 負評價數量 >= 正評價數量 有 [{}] 人\".format(sum(strict_condition(label) for label in te_rating_mat)))\n",
    "print(\"rating正評價數量 >= 0 且 rating負評價數量 >= 0 有 [{}] 人\".format(sum(norm_condition(label) for label in te_rating_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(truth, pred_mat, condition_fn=None, k=10, label_thres=4):\n",
    "    hits, total = 0, 0\n",
    "    for label, pr in zip(truth, pred_mat):\n",
    "        if not condition_fn(label): continue\n",
    "\n",
    "        top_k_ind = (pr * (label != 0)).argsort()[::-1][:k]\n",
    "        hits += sum(label[top_k_ind] >= label_thres)\n",
    "        total += k\n",
    "    return hits / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_mat = np.zeros_like(te_rating_mat)\n",
    "pred_mat[te.userId, te.movieId] = pred\n",
    "    \n",
    "print( \"strict condition precision at 10: \", precision_at_k(te_rating_mat, pred_mat, strict_condition, k=10) )\n",
    "print( \"norm condition precision at 10: \", precision_at_k(te_rating_mat, pred_mat, norm_condition, k=10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG: Normalized Discounted Cumulative Gain\n",
    "1. A measure of ranking quality.\n",
    "2. loop 每一位user, prediciton score排序後計算NDCG\n",
    "    <br/>$$ DCG_p = \\sum^p_{i = 1} \\frac{2^{rel_i} - 1}{log_2(i + 1)} $$<br/>\n",
    "3. IDCG: Ideal DCG, 為理想狀態下的DCG分數, 即model全部命中的DCG分數, 而NDCG: Normalized DCG, 公式如下\n",
    "    <br/>$$ NDCG_p = \\sum^p_{i = 1} \\frac{DCG_p}{IDCG_p} $$<br/>\n",
    "4. 所以NDCG是一個比值, 介於0 ~ 1之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_user_ndcg(label_mat, pred_mat, cond_fn, label_thres=4, k=10):\n",
    "    \"\"\"avg of all user ndcg score\"\"\"\n",
    "    tot_ndcg, actual_cnt = 0, 0\n",
    "    for i, (label, score) in enumerate(zip(label_mat, pred_mat)):\n",
    "        if not cond_fn(label): continue\n",
    "\n",
    "        ndcg = single_user_ndcg(label, score, k=10)\n",
    "        if ndcg is not None:\n",
    "            tot_ndcg += ndcg\n",
    "            actual_cnt += 1\n",
    "    return tot_ndcg / actual_cnt\n",
    "\n",
    "def single_user_ndcg(label, score, label_thres=4, k=10):\n",
    "    \"\"\"single user ndcg score\"\"\"\n",
    "    nnz = label.nonzero()[0]\n",
    "    # if np.sum(label >= label_thres) < k: return None\n",
    "    label, score = label[nnz], score[nnz]\n",
    "    label = (label >= label_thres).astype(int)\n",
    "    return ndcg_score(label, score, k)\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank k\"\"\"\n",
    "    best = dcg_score(y_true, y_true, k, gains)\n",
    "    actual = dcg_score(y_true, y_score, k, gains)\n",
    "    return actual / best\n",
    "\n",
    "def dcg_score(y_true, y_score, k=10, gains=\"exponential\"):\n",
    "    \"\"\"Discounted cumulative gain (DCG) at rank k\"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "\n",
    "    # highest rank is 1 so +2 instead of +1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mat = np.zeros_like(te_rating_mat)\n",
    "pred_mat[te.userId, te.movieId] = pred\n",
    "    \n",
    "strict_ndcg = all_user_ndcg(te_rating_mat, pred_mat, strict_condition, label_thres=4, k=10)\n",
    "norm_ndcg = all_user_ndcg(te_rating_mat, pred_mat, norm_condition, label_thres=4, k=10)\n",
    "print(\"strict condition ndcg at 10: \", strict_ndcg)\n",
    "print(\"norm condition ndcg at 10: \", norm_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## Baseline: 不經過訓練隨機產生預測值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyPredMat = np.random.random((n_users, n_movies))\n",
    "draw_roc_curve((te_rating_mat >= 4).astype(int).ravel(), dummyPredMat.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不經過訓練隨機產生預測值 RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = te_rating_mat > 0\n",
    "print(\"rmse of dummy model(valid data): \", np.sqrt(np.mean( (te_rating_mat[mask] - dummyPredMat[mask])**2)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不經過訓練隨機產生預測值 precision at 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"strict condition precision at 10: \", precision_at_k(te_rating_mat, dummyPredMat, strict_condition, k=10) )\n",
    "print( \"norm condition precision at 10: \", precision_at_k(te_rating_mat, dummyPredMat, norm_condition, k=10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不經過訓練隨機產生預測值 ndcg at 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_ndcg = all_user_ndcg(te_rating_mat, dummyPredMat, strict_condition, label_thres=4, k=10)\n",
    "norm_ndcg = all_user_ndcg(te_rating_mat, dummyPredMat, norm_condition, label_thres=4, k=10)\n",
    "print(\"strict condition ndcg at 10: \", strict_ndcg)\n",
    "print(\"norm condition ndcg at 10: \", norm_ndcg)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
