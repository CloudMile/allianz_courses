{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6ZkmV_Ly4QfR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting started: Introduction to Keras\n",
        "\n",
        "The core data structure of Keras is a __model__, a way to organize layers. The simplest type of model is the [`Sequential`](https://keras.io/getting-started/sequential-model-guide) model, a linear stack of layers. For more complex architectures, you should use the [Keras functional API](https://keras.io/getting-started/functional-api-guide), which allows to build arbitrary graphs of layers.\n",
        "\n",
        "\n",
        "Here is the `Sequential` model:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "```\n",
        "\n",
        "Stacking layers is as easy as `.add()`:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "```\n",
        "\n",
        "Once your model looks good, configure its learning process with `.compile()`:\n",
        "\n",
        "```python\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).\n",
        "```python\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
        "```\n",
        "\n",
        "You can now iterate on your training data in batches:\n",
        "\n",
        "```python\n",
        "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
        "```\n",
        "\n",
        "Evaluate your performance in one line:\n",
        "\n",
        "```python\n",
        "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
        "```\n",
        "\n",
        "Or generate predictions on new data:\n",
        "\n",
        "```python\n",
        "classes = model.predict(x_test, batch_size=128)\n",
        "```\n",
        "\n",
        "Building a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?\n"
      ]
    },
    {
      "metadata": {
        "id": "9OWIA1k1U2T9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Necessary Library"
      ]
    },
    {
      "metadata": {
        "id": "MZL_r7cGHUxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "me6WovuPek-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos]\n",
        "\n",
        "get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "geI8IW1BiLxL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(2017)\n",
        "tf.set_random_seed(2017)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4MMl5E8TUzRD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "metadata": {
        "id": "xkFZh347Hdwf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wx3xrroK8YcY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "metadata": {
        "id": "a3dV0Q9ur6cK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIS_EzSz9ZRH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://storage.googleapis.com/allianz-course/data/fashion_mnist_label.jpg =200x400)"
      ]
    },
    {
      "metadata": {
        "id": "ygSkiSTyHi5k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EBppeucZ8gz4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# preview some images in each class\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(4):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    \n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(str(train_labels[i])+': '+class_names[train_labels[i]], size=25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NGaphirWHgMa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Train image shape:{0}\".format(train_images.shape))\n",
        "print(\"Test image shape:{0}\".format(test_images.shape))\n",
        "print(\"Train class: {0}\".format(np.unique(train_labels)))\n",
        "print(\"Test class: {0}\".format(np.unique(test_labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RwoktLzynhwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "metadata": {
        "id": "-8E3fGplpZyc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Normalizing(feature_scaling)\n",
        "\n",
        "\n",
        "In machine learning, we want the model to be able to learn the real structures instead of dealing with the scales difference. Therefore, we would normalize data before feeding it into model.\n",
        "\n",
        "![Normalizing(feature_scaling)](https://storage.googleapis.com/allianz-course/data/feature_scaling.jpg =300x150)"
      ]
    },
    {
      "metadata": {
        "id": "O6FJqsbKCZck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "print('Max value in this image: {}'.format(np.amax(train_images[0])))\n",
        "print('Min value in this image: {}'.format(np.amin(train_images[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "836Bwgl1n9Ml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Normalize Data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PxpbZqwIeyq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **One-hot encoding**\n",
        "\n",
        "The label now is 0, 1, 2, 3, ...., 9 and they are 'symbols' of classes. However, if we use 0,1,2,3,...,9 to indicate classes, there would be ordinal relationship between the classes.  Therefore, one-hot encoding method is applied to label before training.\n",
        "\n",
        "![alt text](https://storage.googleapis.com/allianz-course/data/one-hot.jpg =600x400)"
      ]
    },
    {
      "metadata": {
        "id": "epQZqJejnXwd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels = keras.utils.to_categorical(train_labels, num_classes=10)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "smB9CUPMBS5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lVOavh0mTyJz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ]
    },
    {
      "metadata": {
        "id": "5eaZIcm5Qdpe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **(Lab 2-a) Basic Model: model_sig_sgd_001**\n",
        "* Hidden Layer: [ 128 , 64 ]\n",
        "* Activation funcition in Hidden Layers: Sigmoid\n",
        "* Optimizer: SGD\n",
        "* Learning Rate: 0.001\n",
        "* Training Epoch: 20\n",
        "\n",
        "\n",
        "***Hint***: \n",
        "\n",
        "To add dense layer in keras, use: \n",
        "``` python\n",
        "# n is number of neurons\n",
        "# act is activation function, such as 'sigmoid', 'relu', 'softmax'\n",
        "model.add(Dense(n, activation = act))\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Yd44UC6BTw-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean session fisrt\n",
        "K.clear_session()\n",
        "\n",
        "# Start building the model \n",
        "model_sig_sgd_001 = Sequential()\n",
        "model_sig_sgd_001.add(Flatten(input_shape=(28, 28)))\n",
        "model_sig_sgd_001.add(Dense(128, activation = 'sigmoid'))\n",
        "\n",
        "############# START CODING HERE #############\n",
        "\n",
        "# add one dense layer with 64 neurons and with 'sigmoid' activation function (~ 1 line)\n",
        "\n",
        "\n",
        "############# END CODING HERE ###############\n",
        "\n",
        "model_sig_sgd_001.add(Dense(10, activation='softmax'))\n",
        "opt = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
        "model_sig_sgd_001.compile(loss='categorical_crossentropy',\n",
        "                          optimizer = opt,\n",
        "                          metrics = ['accuracy'])\n",
        "\n",
        "# Use .summary() to see model details\n",
        "model_sig_sgd_001.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MI74vf65uQLe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ]
    },
    {
      "metadata": {
        "id": "13U-Ho6TudJ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_sig_sgd_001.add(Dense(64, activation = 'sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3h-s3ZGuiwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sig_sgd_001 = model_sig_sgd_001.fit(train_images, \n",
        "                                          train_labels, \n",
        "                                          epochs = 20, \n",
        "                                          batch_size = 128, \n",
        "                                          validation_split = 0.05, \n",
        "                                          shuffle = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DJmmtfIdUh3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the training result\n",
        "plt.figure()\n",
        "epoch = len(train_sig_sgd_001.history[\"loss\"])\n",
        "plt.plot(np.arange(1, epoch+1), train_sig_sgd_001.history[\"loss\"], label=\"Train Loss\", lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_sig_sgd_001.history[\"val_loss\"], label=\"Val. Loss\", lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_sig_sgd_001.history[\"acc\"], label=\"Train Acc.\", lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_sig_sgd_001.history[\"val_acc\"], label=\"Val. Acc.\", lw=3)\n",
        "plt.xlabel(\"Epoch #\", family='serif', size=14)\n",
        "plt.ylabel(\"Loss/Accuracy\", family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0jHbiztevgOM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "res = model_sig_sgd_001.evaluate(test_images, test_labels)\n",
        "print(f'Testing Accuracy of model_sig_sgd_001: {res[1]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yv6Z5OVTTcyV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **(Lab 2-b) Change activation function to Relu: model_relu_sgd_001**\n",
        "\n",
        "Now, change the activation function in hidden layers to RELU with the following details:\n",
        "\n",
        "* Hidden Layer: [ 128 , 64 ]\n",
        "* Activation funcition in Hidden Layers: **Relu**\n",
        "* Optimizer: SGD\n",
        "* Learning Rate: 0.001\n",
        "* Training Epoch: 20\n",
        "\n",
        "***Hint***: \n",
        "\n",
        "To add dense layer in keras, use: \n",
        "```python\n",
        "# n is number of neurons\n",
        "# act is activation function, such as 'sigmoid', 'relu', 'softmax'\n",
        "model.add(Dense(n, activation = act))\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "MX4t7Dxpv6dx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean session fisrt\n",
        "K.clear_session()\n",
        "\n",
        "# Start building the model \n",
        "model_relu_sgd_001 = Sequential()\n",
        "model_relu_sgd_001.add(Flatten(input_shape=(28, 28)))\n",
        "model_relu_sgd_001.add(Dense(128, activation = 'relu'))\n",
        "\n",
        "############# START CODING HERE #############\n",
        "\n",
        "# add one dense layer with 64 neurons and with 'relu' activation function (~ 1 line)\n",
        "\n",
        "\n",
        "############# END CODING HERE ###############\n",
        "\n",
        "model_relu_sgd_001.add(Dense(10, activation='softmax'))\n",
        "opt = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
        "model_relu_sgd_001.compile(loss='categorical_crossentropy',\n",
        "                          optimizer = opt,\n",
        "                          metrics = ['accuracy'])\n",
        "\n",
        "# Use .summary() to see model details\n",
        "model_relu_sgd_001.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lffh0smzwKOa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution\n"
      ]
    },
    {
      "metadata": {
        "id": "pS7M-FgaxbSv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_relu_sgd_001.add(Dense(64, activation = 'relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gt4N-wJ5eEM7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_relu_sgd_001 = model_relu_sgd_001.fit(train_images, \n",
        "                                            train_labels, \n",
        "                                            epochs = 20, \n",
        "                                            batch_size = 128, \n",
        "                                            validation_split = 0.05, \n",
        "                                            shuffle = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bci29_LdBKu8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "epoch = len(train_relu_sgd_001.history[\"loss\"])\n",
        "plt.plot(np.arange(1, epoch+1), train_sig_sgd_001.history['val_acc'], label='Sigmoid', lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_sgd_001.history['val_acc'], label='Relu', lw=3)\n",
        "plt.ylabel('Accuracy', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NDp58elewEiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "res = model_relu_sgd_001.evaluate(test_images, test_labels)\n",
        "print(f'Testing Accuracy of model_relu_sgd_001: {res[1]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ESR7KeLJXkUZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (Lab 2-c) Change optimizer to Adam: model_relu_adam_001\n",
        "\n",
        "Now, change the optimizer to Adam with the following details:\n",
        "\n",
        "* Hidden Layer: [ 128 , 64 ]\n",
        "* Activation funcition in Hidden Layers: Relu\n",
        "* Optimizer: **Adam**\n",
        "* Learning Rate: 0.001\n",
        "* Training Epoch: 20\n",
        "\n",
        "***Hint***: \n",
        "\n",
        "To use adam optimizer:\n",
        "```python\n",
        "# learning rate is lr\n",
        "opt = tf.train.AdamOptimizer(learning_rate = lr)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "IYoLSwn-Xi83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean session fisrt\n",
        "K.clear_session()\n",
        "\n",
        "# Start building the model \n",
        "model_relu_adam_001 = Sequential()\n",
        "model_relu_adam_001.add(Flatten(input_shape=(28, 28)))\n",
        "model_relu_adam_001.add(Dense(128, activation = 'relu'))\n",
        "model_relu_adam_001.add(Dense(64, activation = 'relu'))\n",
        "model_relu_adam_001.add(Dense(10, activation='softmax'))\n",
        "\n",
        "############# START CODING HERE #############\n",
        "\n",
        "# create a adam optimizer with learning rate 0.001 (~ 1 line)(hint: tf.train.AdamOptimizer(learning_rate = n))\n",
        "\n",
        "\n",
        "############# END CODING HERE ###############\n",
        "\n",
        "model_relu_adam_001.compile(loss='categorical_crossentropy',\n",
        "                           optimizer = opt,\n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "# Use .summary() to see model details\n",
        "model_relu_adam_001.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JqM5qfxJysBz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ]
    },
    {
      "metadata": {
        "id": "12dyfrSGyuGM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# opt = tf.train.AdamOptimizer(learning_rate = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZQDEvh7Yel-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_relu_adam_001 = model_relu_adam_001.fit(train_images, \n",
        "                                              train_labels, \n",
        "                                              epochs = 20, \n",
        "                                              batch_size = 128, \n",
        "                                              validation_split = 0.05, \n",
        "                                              shuffle = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "abOHl-S3X-Jx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "epoch = len(train_relu_adam_001.history[\"loss\"])\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_sgd_001.history['val_acc'], label = 'SGD', lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_adam_001.history['val_acc'], label = 'Adam', lw=3)\n",
        "plt.ylabel('Accuracy', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LyUfnqPMzyIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "res = model_relu_adam_001.evaluate(test_images, test_labels)\n",
        "print(f'Testing Accuracy of model_relu_adam_001: {res[1]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDh4qG3Nem09",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###(Lab 2-d) Change Learning Rate to 0.01: model_relu_adam_01\n",
        "\n",
        "Now, change the learning rate to 0.01 with the following details:\n",
        "\n",
        "* Hidden Layer: [ 128 , 64 ]\n",
        "* Activation funcition in Hidden Layers: Relu\n",
        "* Optimizer: Adam\n",
        "* Learning Rate: **0.01**\n",
        "* Training Epoch: 20\n",
        "\n",
        "***Hint***: \n",
        "\n",
        "To use adam optimizer with learning rate lr:\n",
        "```python\n",
        "# learning rate is lr\n",
        "opt = tf.train.AdamOptimizer(learning_rate = lr)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "mCX5WVVPY2rt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean session fisrt\n",
        "K.clear_session()\n",
        "\n",
        "# Start building the model \n",
        "model_relu_adam_01 = Sequential()\n",
        "model_relu_adam_01.add(Flatten(input_shape=(28, 28)))\n",
        "model_relu_adam_01.add(Dense(128, activation = 'relu'))\n",
        "model_relu_adam_01.add(Dense(64, activation = 'relu'))\n",
        "model_relu_adam_01.add(Dense(10, activation='softmax'))\n",
        "\n",
        "############# START CODING HERE #############\n",
        "\n",
        "# create a adam optimizer with learning rate 0.01 (~ 1 line)(hint: tf.train.AdamOptimizer(learning_rate = n))\n",
        "\n",
        "\n",
        "############# END CODING HERE ###############\n",
        "\n",
        "model_relu_adam_01.compile(loss='categorical_crossentropy',\n",
        "                           optimizer = opt,\n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "# Use .summary() to see model details\n",
        "model_relu_adam_01.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fubkEABf0J8p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ]
    },
    {
      "metadata": {
        "id": "feNt5Tul0NOA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# opt = tf.train.AdamOptimizer(learning_rate = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PG0MD1BcfPxt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_relu_adam_01 = model_relu_adam_01.fit(train_images, \n",
        "                                            train_labels, \n",
        "                                            epochs = 20, \n",
        "                                            batch_size = 128, \n",
        "                                            validation_split = 0.05, \n",
        "                                            shuffle = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HeM7fEYen_7T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epoch = 20\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_adam_001.history['acc'], label='lr='+str(0.001), lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_adam_01.history['acc'], label='lr='+str(0.01), lw=3)\n",
        "\n",
        "plt.ylabel('Acc', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.title('Train Acc.',size=14, family= 'serif')\n",
        "\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_adam_001.history['val_acc'], label='lr='+str(0.001), lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_adam_01.history['val_acc'], label='lr='+str(0.01), lw=3)\n",
        "\n",
        "plt.ylabel('Acc', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.title('Val. Acc.',size=14, family= 'serif')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eZRlBXXl1PVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "res = model_relu_adam_01.evaluate(test_images, test_labels)\n",
        "print(f'Testing Accuracy of model_relu_adam_01: {res[1]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEx5R6sCTl1h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (Lab 2-e) Add more neurons in hidden layers(overfit) : model_large_relu_adam_001\n",
        "\n",
        "Now, change hidden layer neurons to [2048, 1024] with the following details:\n",
        "\n",
        "* Hidden Layer: [ 2048 , 1024 ]\n",
        "* Activation funcition in Hidden Layers: **Relu**\n",
        "* Optimizer: Adam\n",
        "* Learning Rate: 0.001\n",
        "* Training Epoch: 20\n",
        "\n",
        "***Hint***: \n",
        "\n",
        "To use adam optimizer with learning rate lr:\n",
        "```python\n",
        "# learning rate is lr\n",
        "opt = tf.train.AdamOptimizer(learning_rate = lr)\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "M2Y5lPvJDWzD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean session fisrt\n",
        "K.clear_session()\n",
        "\n",
        "# Start building the model \n",
        "model_large_relu_adam_001 = Sequential()\n",
        "model_large_relu_adam_001.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "############# START CODING HERE #############\n",
        "\n",
        "# Create hidden layer with 2048 neurons and relu activation function (~ 1 line)\n",
        "\n",
        "# Create hidden layer with 1024 neurons and relu activation function (~ 1 line)\n",
        "\n",
        "# Create an output layer with 10 neurons and softmax activation function (~ 1 line)\n",
        "\n",
        "# Create a Adam optimizer with learning rate = 0.001 ( ~ 1 line)(hint: tf.train.AdamOptimizer(learning_rate = n))\n",
        "# opt = \n",
        "\n",
        "############# END CODING HERE ###############\n",
        "\n",
        "\n",
        "\n",
        "model_large_relu_adam_001.compile(loss='categorical_crossentropy',\n",
        "                                  optimizer = opt,\n",
        "                                  metrics = ['accuracy'])\n",
        "\n",
        "# Use .summary() to see model details\n",
        "model_large_relu_adam_001.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0wV6VUCT1BLu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ]
    },
    {
      "metadata": {
        "id": "KF7-Bh560_fa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_large_relu_adam_001.add(Dense(2048, activation = 'relu'))\n",
        "# model_large_relu_adam_001.add(Dense(1024, activation = 'relu'))\n",
        "# model_large_relu_adam_001.add(Dense(10, activation='softmax'))\n",
        "# opt = tf.train.AdamOptimizer(learning_rate = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AdUe2F9DetYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_large_relu_adam_001 = model_large_relu_adam_001.fit(train_images, \n",
        "                                                          train_labels, \n",
        "                                                          epochs = 20, \n",
        "                                                          batch_size = 128, \n",
        "                                                          validation_split = 0.05, \n",
        "                                                          shuffle = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GFJpWawyDadC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "epoch = len(train_large_relu_adam_001.history[\"loss\"])\n",
        "plt.plot(np.arange(1, epoch+1), train_large_relu_adam_001.history['loss'], label='Train', lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_large_relu_adam_001.history['val_loss'], label='Validation', lw=3)\n",
        "plt.ylabel('loss', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X_hnjjUDaSUj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Overfit Solution**\n"
      ]
    },
    {
      "metadata": {
        "id": "WE2q3d1sVRVg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### (Lab 2-f) Early Stopping\n",
        "\n",
        "Stop training when a monitored quantity has stopped improving.\n",
        "\n",
        "```python\n",
        "\n",
        "keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, mode='auto')\n",
        "\n",
        "```\n",
        "* monitor: quantity to be monitored.\n",
        "\n",
        "* patience: number of epochs with no improvement after which training will be stopped.\n",
        "\n",
        "* mode: one of {auto, min, max}.    \n",
        "<br/>\n"
      ]
    },
    {
      "metadata": {
        "id": "gTIl8ssDd7nr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean session fisrt\n",
        "K.clear_session()\n",
        "\n",
        "# Start building the model \n",
        "model_large_relu_adam_001_es = Sequential()\n",
        "model_large_relu_adam_001_es.add(Flatten(input_shape=(28, 28)))\n",
        "model_large_relu_adam_001_es.add(Dense(2048, activation = 'relu'))\n",
        "model_large_relu_adam_001_es.add(Dense(1024, activation = 'relu'))\n",
        "model_large_relu_adam_001_es.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
        "\n",
        "model_large_relu_adam_001_es.compile(loss='categorical_crossentropy',\n",
        "                           optimizer = opt,\n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "# Use .summary() to see model details\n",
        "model_large_relu_adam_001_es.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-sDyje_eFmj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a early stopping callback\n",
        "EarlyStopping = keras.callbacks.EarlyStopping(\n",
        "                         monitor='val_loss',\n",
        "                         patience=3,\n",
        "                         mode='auto')\n",
        "\n",
        "callbacks_list = [EarlyStopping] \n",
        "\n",
        "train_model_large_relu_adam_001_es = model_large_relu_adam_001_es.fit(train_images,\n",
        "                                                                      train_labels, \n",
        "                                                                      epochs=20, \n",
        "                                                                      validation_split = 0.05,\n",
        "                                                                      batch_size = 128,\n",
        "                                                                      callbacks=callbacks_list,\n",
        "                                                                      shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dqmjJcIPe9FO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "epoch = len(train_model_large_relu_adam_001_es.history[\"loss\"])\n",
        "plt.plot(np.arange(1, epoch+1), train_model_large_relu_adam_001_es.history['loss'], label='Train', lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_model_large_relu_adam_001_es.history['val_loss'], label='Validation', lw=3)\n",
        "plt.ylabel('loss', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QameKbjibJo7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Save Best Model\n",
        "\n",
        "\n",
        "The latest best model according to the quantity monitored will not be overwritten.\n",
        "```python\n",
        "keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto', period=1)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "xgV_TerlaPUy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (Lab 2-g) Dropout\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://storage.googleapis.com/allianz-course/data/dropout.jpg =400x200)\n",
        "\n",
        "<br/>\n",
        "Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
        "```python\n",
        "keras.layers.Dropout(rate)\n",
        "```\n",
        "rate: float between 0 and 1. Fraction of the input units to drop.\n",
        "\n",
        "**Sample Code:**\n",
        "```python\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=60, activation='relu')\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(30, activation='relu')\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "```\n",
        "\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "vD93wWSCk_wU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean session fisrt\n",
        "K.clear_session()\n",
        "\n",
        "# Start building the model \n",
        "model_large_relu_adam_001_do = Sequential()\n",
        "model_large_relu_adam_001_do.add(Flatten(input_shape=(28, 28)))\n",
        "model_large_relu_adam_001_do.add(Dense(2048, activation = 'relu'))\n",
        "model_large_relu_adam_001_do.add(Dropout(0.5))\n",
        "model_large_relu_adam_001_do.add(Dense(1024, activation = 'relu'))\n",
        "model_large_relu_adam_001_do.add(Dropout(0.5))\n",
        "model_large_relu_adam_001_do.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
        "\n",
        "model_large_relu_adam_001_do.compile(loss='categorical_crossentropy',\n",
        "                           optimizer = opt,\n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "# Use .summary() to see model details\n",
        "model_large_relu_adam_001_do.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TTuRREJ1ldCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_model_large_relu_adam_001_do = model_large_relu_adam_001_do.fit(train_images,\n",
        "                                                                      train_labels, \n",
        "                                                                      epochs=20, \n",
        "                                                                      validation_split = 0.05,\n",
        "                                                                      batch_size = 128,\n",
        "                                                                      shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wHwHeSAAlX4k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "epoch = len(train_model_large_relu_adam_001_do.history[\"loss\"])\n",
        "plt.plot(np.arange(1, epoch+1), train_model_large_relu_adam_001_do.history['loss'], label='Train', lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_model_large_relu_adam_001_do.history['val_loss'], label='Validation', lw=3)\n",
        "plt.ylabel('loss', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAfEW1mWdixY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "CXeT3-FCSiq_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, BatchNormalization, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2mYvKZgOpr-b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (lab 2-h) Create a basic CNN model"
      ]
    },
    {
      "metadata": {
        "id": "R2EoVGQGSPe9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "model_basic_cnn = keras.Sequential()\n",
        "\n",
        "model_basic_cnn.add(Conv2D(filters=32,\n",
        "                           kernel_size=(3,3),\n",
        "                           input_shape=(28,28,1),\n",
        "                           padding='same',\n",
        "                           activation='relu'))\n",
        "\n",
        "model_basic_cnn.add(MaxPool2D(pool_size=(2,2),\n",
        "                              strides=(2,2)))\n",
        "\n",
        "model_basic_cnn.add(Conv2D(filters=64,\n",
        "                           kernel_size=(3,3),\n",
        "                           padding='same',\n",
        "                           activation='relu'))\n",
        "\n",
        "model_basic_cnn.add(MaxPool2D(pool_size=(2,2),\n",
        "                              strides=(2,2)))\n",
        "\n",
        "model_basic_cnn.add(Conv2D(filters=128,\n",
        "                           kernel_size=(3,3),\n",
        "                           padding='same',\n",
        "                           activation='relu'))\n",
        "\n",
        "model_basic_cnn.add(MaxPool2D(pool_size=(2,2),\n",
        "                              strides=(2,2)))\n",
        "\n",
        "model_basic_cnn.add(Flatten())\n",
        "\n",
        "model_basic_cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_basic_cnn.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GLX_MkIBhdXe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opfunc = tf.train.AdamOptimizer(learning_rate = 0.001) \n",
        "\n",
        "model_basic_cnn.compile(optimizer = opfunc, \n",
        "                        loss = 'categorical_crossentropy',\n",
        "                        metrics = ['accuracy'])\n",
        "\n",
        "train_basic_cnn = model_basic_cnn.fit(np.expand_dims(train_images, -1), \n",
        "                                      train_labels, \n",
        "                                      batch_size=256,\n",
        "                                      epochs=20, \n",
        "                                      validation_split = 0.05,\n",
        "                                      shuffle = False,\n",
        "                                      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7fVF1yAiMHm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_model_basic_cnn = model_basic_cnn.evaluate(np.expand_dims(test_images, -1) , test_labels)\n",
        "print(f'Testing Accuracy of the Basic CNN: {test_model_basic_cnn[1]}')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hqwzJlmRxf9L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (lab 2-e) Create a advanced CNN model"
      ]
    },
    {
      "metadata": {
        "id": "mt5oVlm-WQLC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "model_cnn = keras.Sequential()\n",
        "\n",
        "model_cnn.add(Conv2D(filters=32,\n",
        "                     kernel_size=(3,3),\n",
        "                     input_shape=(28,28,1),\n",
        "                     padding='valid',\n",
        "                     use_bias=False,\n",
        "                     activation=None))\n",
        "\n",
        "model_cnn.add(BatchNormalization())\n",
        "\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(Conv2D(filters=64,\n",
        "                     kernel_size=(3,3),\n",
        "                     padding='valid',\n",
        "                     use_bias=False,\n",
        "                     activation=None))\n",
        "\n",
        "model_cnn.add(BatchNormalization())\n",
        "\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(Conv2D(filters=128,\n",
        "                     kernel_size=(3,3),\n",
        "                     padding='same',\n",
        "                     use_bias=False,\n",
        "                     activation=None))\n",
        "\n",
        "model_cnn.add(BatchNormalization())  \n",
        "\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(MaxPool2D(pool_size=(2,2),\n",
        "                        strides=(2,2)))\n",
        "\n",
        "model_cnn.add(Conv2D(filters=256,\n",
        "                     kernel_size=(3,3),\n",
        "                     padding='valid',\n",
        "                     use_bias=False,\n",
        "                     activation=None))\n",
        "\n",
        "model_cnn.add(BatchNormalization())  \n",
        "\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(Conv2D(filters=512,\n",
        "                     kernel_size=(3,3),\n",
        "                     padding='valid',\n",
        "                     use_bias=False,\n",
        "                     activation=None))\n",
        "\n",
        "model_cnn.add(BatchNormalization())\n",
        "\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(MaxPool2D(pool_size=(8,8),\n",
        "                        strides=(1,1)))  \n",
        "\n",
        "model_cnn.add(Flatten()) \n",
        "\n",
        "model_cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_cnn.summary()\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbNO3oSofz7F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opfunc = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
        "\n",
        "model_cnn.compile(optimizer = opfunc, \n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics = ['accuracy'])\n",
        "\n",
        "train_model_cnn = model_cnn.fit(np.expand_dims(train_images, -1),\n",
        "                                train_labels, \n",
        "                                batch_size=256,\n",
        "                                epochs=20, \n",
        "                                validation_split = 0.05,\n",
        "                                verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRBnrGyYr5A2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "epoch = len(train_relu_adam_001.history[\"loss\"])\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_adam_001.history['val_acc'], label='DNN', lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_basic_cnn.history['val_acc'], label='Basic CNN', lw=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_model_cnn.history['val_acc'], label='Advanced CNN', lw=3)\n",
        "plt.ylabel('Accuracy', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A0H1xKr2XXzr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_result=model_cnn.evaluate(np.expand_dims(test_images, -1)  , test_labels)\n",
        "print(f'Testing Accuracy of the Advanced CNN: {test_result[1]}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gYekeHaJssrw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (lab 2-f) MobileNet"
      ]
    },
    {
      "metadata": {
        "id": "8vEm6gRCx2qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.layers import Lambda, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nwGgW61oSOC1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "height,width = 56, 56\n",
        "\n",
        "input_image = Input(shape=(height,width))\n",
        "\n",
        "input_image_ = Lambda(lambda x: K.repeat_elements(K.expand_dims(x,3),3,3))(input_image)\n",
        "\n",
        "model_mobilenet_base = MobileNet(input_tensor=input_image_,\n",
        "                                 weights='imagenet',\n",
        "                                 include_top=False, \n",
        "                                 pooling='avg')\n",
        "\n",
        "x = Dropout(0.5)(model_mobilenet_base.output)\n",
        "\n",
        "predict = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_mobilenet = Model(inputs=input_image, outputs=predict)\n",
        "\n",
        "opfunc = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
        "\n",
        "model_mobilenet.compile(optimizer=opfunc, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_mobilenet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EAWvmDp6lil6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resized_train_images = np.array([cv2.resize(x, (height, width)).astype(float) for x in train_images])\n",
        "\n",
        "train_mobilenet = model_mobilenet.fit(resized_train_images, \n",
        "                                          train_labels,\n",
        "                                          batch_size=256,\n",
        "                                          epochs=20, \n",
        "                                          validation_split=0.05,                           \n",
        "                                          verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NzAvPNg_x6Bl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resized_test_images = np.array([cv2.resize(x, (height, width)).astype(float) for x in test_images])\n",
        "test_result = model_mobilenet.evaluate(resized_test_images , test_labels)\n",
        "print(f'Testing Accuracy of MobileNet: {test_result[1]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u3T7Kc35a3Qc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "epoch = len(train_relu_adam_001.history[\"loss\"])\n",
        "plt.plot(np.arange(1, epoch+1), train_relu_adam_001.history['val_acc'], label='DNN', lx=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_basic_cnn.history['val_acc'], label='Basic CNN', lx=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_model_cnn.history['val_acc'], label='Advanced CNN', lx=3)\n",
        "plt.plot(np.arange(1, epoch+1), train_mobilenet.history['val_acc'], label='MobileNet', lx=3)\n",
        "\n",
        "plt.ylabel('Accuracy', family='serif', size=14)\n",
        "plt.xlabel('Epoch #', family='serif', size=14)\n",
        "plt.xticks(np.arange(1, epoch+1))\n",
        "plt.xlim([1, epoch])\n",
        "plt.legend(prop={'size':14, 'family':'serif'})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "haqf-V7_CXB4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'Testing Accuracy of MobileNet: {test_result[1]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lokydi5t_fZM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}