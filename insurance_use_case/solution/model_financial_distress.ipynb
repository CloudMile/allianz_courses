{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X6TzudIkLSb2"
   },
   "source": [
    "## Load Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3826,
     "status": "ok",
     "timestamp": 1538625947853,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "_OceWebGEClz",
    "outputId": "979cfb33-6793-4122-a947-73d1bd147a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: seaborn in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from seaborn) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14.0 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.15.2 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from seaborn) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=1.4.3 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2018.5)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in d:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (39.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!pip install seaborn --upgrade\n",
    "\n",
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf, cv2\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, LabelBinarizer\n",
    "from sklearn.metrics import auc, roc_curve, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, BatchNormalization, Activation, Input, Dropout, Embedding, Flatten, Input\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras import regularizers\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_result(hist):\n",
    "    plt.figure(figsize=(16, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(hist.history['loss'], label='tr_loss')\n",
    "    plt.plot(hist.history['val_loss'], label='vl_loss')\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(hist.history['acc'], label='acc')\n",
    "    plt.plot(hist.history['val_acc'], label='val_acc')\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "def draw_roc_curve(y, pred):\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    fprRf, tprRf, _ = roc_curve(y, pred, pos_label=1)\n",
    "    auc_scr = auc(fprRf, tprRf)\n",
    "    print(\"auc:\", auc_scr)\n",
    "    f, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.plot(fprRf, tprRf, label='ROC CURVE')\n",
    "    ax.set_xlabel('False positive rate')\n",
    "    ax.set_ylabel('True positive rate')\n",
    "    ax.set_title('Area Under Curve(ROC) (score: {:.4f})'.format(auc_scr))\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "import financial_distress_functions as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeEHBniStlgU"
   },
   "source": [
    "## Data Schema\n",
    "\n",
    "Column name     | Description\n",
    "             ---|---\n",
    "RorNumber       |    Row number\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ps1HdA6twJck"
   },
   "source": [
    "# Purpose: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1451,
     "status": "ok",
     "timestamp": 1538625951034,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "_UOyp6tUECl1",
    "outputId": "6b14c68e-7fb2-4959-dfec-8d970505dc52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>distress_num</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>...</th>\n",
       "      <th>x74</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>1.28100</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.87454</td>\n",
       "      <td>1.21640</td>\n",
       "      <td>0.060940</td>\n",
       "      <td>0.188270</td>\n",
       "      <td>0.52510</td>\n",
       "      <td>...</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>1.27000</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.82067</td>\n",
       "      <td>1.00490</td>\n",
       "      <td>-0.014080</td>\n",
       "      <td>0.181040</td>\n",
       "      <td>0.62288</td>\n",
       "      <td>...</td>\n",
       "      <td>107.090</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.325390</td>\n",
       "      <td>1.05290</td>\n",
       "      <td>-0.059379</td>\n",
       "      <td>0.92242</td>\n",
       "      <td>0.72926</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.044865</td>\n",
       "      <td>0.43292</td>\n",
       "      <td>...</td>\n",
       "      <td>120.870</td>\n",
       "      <td>36.07</td>\n",
       "      <td>35.273</td>\n",
       "      <td>17.000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.566570</td>\n",
       "      <td>1.11310</td>\n",
       "      <td>-0.015229</td>\n",
       "      <td>0.85888</td>\n",
       "      <td>0.80974</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>0.091033</td>\n",
       "      <td>0.67546</td>\n",
       "      <td>...</td>\n",
       "      <td>54.806</td>\n",
       "      <td>39.80</td>\n",
       "      <td>38.377</td>\n",
       "      <td>17.167</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.325390</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>1.06230</td>\n",
       "      <td>0.107020</td>\n",
       "      <td>0.81460</td>\n",
       "      <td>0.83593</td>\n",
       "      <td>0.199960</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>...</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>29</td>\n",
       "      <td>1.251000</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>1.05580</td>\n",
       "      <td>0.081916</td>\n",
       "      <td>0.87949</td>\n",
       "      <td>0.68673</td>\n",
       "      <td>0.142630</td>\n",
       "      <td>0.043102</td>\n",
       "      <td>0.77198</td>\n",
       "      <td>...</td>\n",
       "      <td>107.090</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.200200</td>\n",
       "      <td>0.97059</td>\n",
       "      <td>0.076064</td>\n",
       "      <td>0.90677</td>\n",
       "      <td>0.80980</td>\n",
       "      <td>0.165920</td>\n",
       "      <td>-0.024649</td>\n",
       "      <td>0.73660</td>\n",
       "      <td>...</td>\n",
       "      <td>120.870</td>\n",
       "      <td>36.07</td>\n",
       "      <td>35.273</td>\n",
       "      <td>17.000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.234800</td>\n",
       "      <td>1.05900</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.81811</td>\n",
       "      <td>0.87599</td>\n",
       "      <td>0.234450</td>\n",
       "      <td>0.045576</td>\n",
       "      <td>0.78727</td>\n",
       "      <td>...</td>\n",
       "      <td>54.806</td>\n",
       "      <td>39.80</td>\n",
       "      <td>38.377</td>\n",
       "      <td>17.167</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>29</td>\n",
       "      <td>1.200200</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.340500</td>\n",
       "      <td>1.12450</td>\n",
       "      <td>0.147840</td>\n",
       "      <td>0.75871</td>\n",
       "      <td>1.07990</td>\n",
       "      <td>0.276440</td>\n",
       "      <td>0.089408</td>\n",
       "      <td>0.80356</td>\n",
       "      <td>...</td>\n",
       "      <td>59.806</td>\n",
       "      <td>44.53</td>\n",
       "      <td>42.822</td>\n",
       "      <td>15.500</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.234800</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.047400</td>\n",
       "      <td>1.59980</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>0.54615</td>\n",
       "      <td>1.31270</td>\n",
       "      <td>0.369480</td>\n",
       "      <td>0.296640</td>\n",
       "      <td>0.85364</td>\n",
       "      <td>...</td>\n",
       "      <td>66.262</td>\n",
       "      <td>52.74</td>\n",
       "      <td>49.206</td>\n",
       "      <td>15.500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.340500</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company  Time  distress_num       x1        x2       x3       x4        x5  \\\n",
       "0        1     1      0.010636  1.28100  0.022934  0.87454  1.21640  0.060940   \n",
       "1        1     2     -0.455970  1.27000  0.006454  0.82067  1.00490 -0.014080   \n",
       "2        1     3     -0.325390  1.05290 -0.059379  0.92242  0.72926  0.020476   \n",
       "3        1     4     -0.566570  1.11310 -0.015229  0.85888  0.80974  0.076037   \n",
       "4        2     1      1.357300  1.06230  0.107020  0.81460  0.83593  0.199960   \n",
       "5        2     2      0.007188  1.05580  0.081916  0.87949  0.68673  0.142630   \n",
       "6        2     3      1.200200  0.97059  0.076064  0.90677  0.80980  0.165920   \n",
       "7        2     4      2.234800  1.05900  0.130200  0.81811  0.87599  0.234450   \n",
       "8        2     5      1.340500  1.12450  0.147840  0.75871  1.07990  0.276440   \n",
       "9        2     6      2.047400  1.59980  0.262460  0.54615  1.31270  0.369480   \n",
       "\n",
       "         x6       x7 ...       x74    x75     x76     x77   x78  x79  x80  \\\n",
       "0  0.188270  0.52510 ...    85.437  27.07  26.102  16.000  16.0  0.2   22   \n",
       "1  0.181040  0.62288 ...   107.090  31.31  30.194  17.000  16.0  0.4   22   \n",
       "2  0.044865  0.43292 ...   120.870  36.07  35.273  17.000  15.0 -0.2   22   \n",
       "3  0.091033  0.67546 ...    54.806  39.80  38.377  17.167  16.0  5.6   22   \n",
       "4  0.047800  0.74200 ...    85.437  27.07  26.102  16.000  16.0  0.2   29   \n",
       "5  0.043102  0.77198 ...   107.090  31.31  30.194  17.000  16.0  0.4   29   \n",
       "6 -0.024649  0.73660 ...   120.870  36.07  35.273  17.000  15.0 -0.2   29   \n",
       "7  0.045576  0.78727 ...    54.806  39.80  38.377  17.167  16.0  5.6   29   \n",
       "8  0.089408  0.80356 ...    59.806  44.53  42.822  15.500  14.0  2.1   29   \n",
       "9  0.296640  0.85364 ...    66.262  52.74  49.206  15.500  12.0 -6.4   29   \n",
       "\n",
       "        x81  x82  x83  \n",
       "0  0.060390   30   49  \n",
       "1  0.010636   31   50  \n",
       "2 -0.455970   32   51  \n",
       "3 -0.325390   33   52  \n",
       "4  1.251000    7   27  \n",
       "5  1.357300    8   28  \n",
       "6  0.007188    9   29  \n",
       "7  1.200200   10   30  \n",
       "8  2.234800   11   31  \n",
       "9  1.340500   12   32  \n",
       "\n",
       "[10 rows x 86 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw = pd.read_csv(\"https://storage.googleapis.com/allianz-course/data/raw_tr_financial_churn.csv\")\n",
    "# raw_vl = pd.read_csv(\"https://storage.googleapis.com/allianz-course/data/raw_vl_financial_churn.csv\")\n",
    "# raw.head()\n",
    "raw = pd.read_csv('https://storage.googleapis.com/allianz-course/data/raw_financial_distess.csv').rename(columns={'Financial Distress': 'distress_num'})\n",
    "raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoyVZct4tpFa"
   },
   "source": [
    "## Features setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plpAXiiatNgD"
   },
   "outputs": [],
   "source": [
    "catg_features = ['x80'] # 'Company', \n",
    "num_features = [f'x{i}' for i in range(1, 84) if i != 80]\n",
    "# embedding_features = catg_features + ['binn_tenure', 'binn_MonthlyCharges', 'binn_TotalCharges']\n",
    "label = 'distress_catg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>distress_num</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>...</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "      <th>distress_catg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>1.2810</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.87454</td>\n",
       "      <td>1.21640</td>\n",
       "      <td>0.060940</td>\n",
       "      <td>0.188270</td>\n",
       "      <td>0.52510</td>\n",
       "      <td>...</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>1.2700</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.82067</td>\n",
       "      <td>1.00490</td>\n",
       "      <td>-0.014080</td>\n",
       "      <td>0.181040</td>\n",
       "      <td>0.62288</td>\n",
       "      <td>...</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.325390</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>-0.059379</td>\n",
       "      <td>0.92242</td>\n",
       "      <td>0.72926</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.044865</td>\n",
       "      <td>0.43292</td>\n",
       "      <td>...</td>\n",
       "      <td>36.07</td>\n",
       "      <td>35.273</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>1.0623</td>\n",
       "      <td>0.107020</td>\n",
       "      <td>0.81460</td>\n",
       "      <td>0.83593</td>\n",
       "      <td>0.199960</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>...</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>29</td>\n",
       "      <td>1.251000</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>1.0558</td>\n",
       "      <td>0.081916</td>\n",
       "      <td>0.87949</td>\n",
       "      <td>0.68673</td>\n",
       "      <td>0.142630</td>\n",
       "      <td>0.043102</td>\n",
       "      <td>0.77198</td>\n",
       "      <td>...</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company  Time  distress_num      x1        x2       x3       x4        x5  \\\n",
       "0        1     1      0.010636  1.2810  0.022934  0.87454  1.21640  0.060940   \n",
       "1        1     2     -0.455970  1.2700  0.006454  0.82067  1.00490 -0.014080   \n",
       "2        1     3     -0.325390  1.0529 -0.059379  0.92242  0.72926  0.020476   \n",
       "4        2     1      1.357300  1.0623  0.107020  0.81460  0.83593  0.199960   \n",
       "5        2     2      0.007188  1.0558  0.081916  0.87949  0.68673  0.142630   \n",
       "\n",
       "         x6       x7      ...          x75     x76   x77   x78  x79  x80  \\\n",
       "0  0.188270  0.52510      ...        27.07  26.102  16.0  16.0  0.2   22   \n",
       "1  0.181040  0.62288      ...        31.31  30.194  17.0  16.0  0.4   22   \n",
       "2  0.044865  0.43292      ...        36.07  35.273  17.0  15.0 -0.2   22   \n",
       "4  0.047800  0.74200      ...        27.07  26.102  16.0  16.0  0.2   29   \n",
       "5  0.043102  0.77198      ...        31.31  30.194  17.0  16.0  0.4   29   \n",
       "\n",
       "        x81  x82  x83  distress_catg  \n",
       "0  0.060390   30   49              0  \n",
       "1  0.010636   31   50              0  \n",
       "2 -0.455970   32   51              0  \n",
       "4  1.251000    7   27              0  \n",
       "5  1.357300    8   28              0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rolling mean\n",
    "# raw['rolling_mean'] = (raw.groupby('Company', group_keys=False)\n",
    "#                           .apply(lambda pipe: pipe['distress_num'].rolling(window=3).mean().fillna(0))\n",
    "#                           .values)\n",
    "\n",
    "# Split train valid\n",
    "# def split_fn(pipe):\n",
    "#     lens = len(pipe)\n",
    "#     ret = np.ones(lens)\n",
    "#     if lens >= 5:\n",
    "#         split_size = int(lens * 0.36)\n",
    "#         ret[-split_size:] = 0\n",
    "#     return ret\n",
    "\n",
    "# Split train valid\n",
    "def split_fn(pipe):\n",
    "    lens = len(pipe)\n",
    "    ret = np.ones(lens)\n",
    "    if lens > 1:\n",
    "        split_size = int(lens * 0.36)\n",
    "        ret[-1:] = 0\n",
    "    return ret\n",
    "\n",
    "raw['distress_catg'] = (raw.distress_num <= -0.5).astype(int)\n",
    "raw['is_train'] = np.concatenate(raw.groupby('Company').apply(split_fn).values)\n",
    "raw_vl = raw.query(\"is_train == 0\").drop('is_train', 1)\n",
    "raw = raw.query(\"is_train == 1\").drop('is_train', 1)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.to_csv('../data/raw_tr_financial_distree.csv', index=False)\n",
    "raw_vl.to_csv('../data/raw_vl_financial_distree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distress_num    1.000000\n",
       "x10             0.315136\n",
       "x25             0.364427\n",
       "x48             0.432697\n",
       "x81             0.435405\n",
       "Name: distress_num, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = raw.corr()\n",
    "corr['distress_num'][(corr['distress_num'] <= -0.3) | (corr['distress_num'] >= 0.3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oCud9-1Esa6S"
   },
   "source": [
    "## Base Feature Preprocessing\n",
    "\n",
    "* Normalize ofr numeric features\n",
    "* One Hot Encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(raw, is_train=True, status=None):\n",
    "    data = raw.copy()\n",
    "    \n",
    "    if is_train:\n",
    "        status = {'scaler': None, \n",
    "                  'mapper': defaultdict(LabelBinarizer),\n",
    "                  'woe_mapper': {},\n",
    "                  'binn_mapper': {},\n",
    "                  'freq_mapper': {},\n",
    "                  'mean_mapper': {},\n",
    "                  'rfm_mapper': {}}\n",
    "\n",
    "    catg_ftrs = catg_features.copy()\n",
    "        \n",
    "    # Numeric binning to categorical features\n",
    "    do_binning(catg_ftrs, status, data, is_train)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "    catg_part = pd.DataFrame()\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    # catg_part = pd.get_dummies(data[catg_ftrs])\n",
    "    do_onehot(catg_ftrs, catg_part, status, data, is_train)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "    # Embedding, simple indexing categorical features, actual embedding function in keras\n",
    "    # do_embedding(catg_ftrs, catg_part, status, data, is_train)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "    # RFM\n",
    "    do_rfm(catg_ftrs, catg_part, status, data, is_train)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    \n",
    "    # WOE encoding\n",
    "    do_woe_encoding(catg_ftrs, catg_part, status, data, is_train)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "    # Frequency encoding, target mean encoding\n",
    "    do_target_encoding(catg_ftrs, catg_part, status, data, is_train)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "    # Normalize\n",
    "    num_part = do_norm(num_features, status, data, is_train)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Merge categorical, numeric features\n",
    "    data_x, data_y = pd.concat([catg_part, num_part], 1), data['distress_catg'].copy()\n",
    "    \n",
    "    # Include quadratic term, cube term\n",
    "    do_nth_order_polynominal(num_features, data_x)\n",
    "    # ----------------------------------------------------------------------------------------- \n",
    "    # todo hack\n",
    "    # data_x['distress_num'] = data['distress_num'].values\n",
    "    return data_x, data_y, status\n",
    "\n",
    "\n",
    "do_binning = fn.do_binning\n",
    "do_onehot = fn.do_onehot\n",
    "do_embedding = fn.do_embedding\n",
    "do_woe_encoding = fn.do_woe_encoding\n",
    "do_target_encoding = fn.do_target_encoding\n",
    "do_norm = fn.do_norm\n",
    "do_nth_order_polynominal = fn.do_nth_order_polynominal\n",
    "do_rfm = fn.do_rfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions of Features Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def do_binning(catg_ftrs, status, data, is_train):\n",
    "#     pass\n",
    "\n",
    "# def do_onehot(catg_ftrs, catg_part, status, data, is_train):\n",
    "#     mapper = status['mapper']\n",
    "#     tmp = []\n",
    "#     for catg_col in catg_ftrs:\n",
    "#         if is_train:\n",
    "#             result = mapper[catg_col].fit_transform(data[catg_col])\n",
    "#         else:\n",
    "#             result = mapper[catg_col].transform(data[catg_col])\n",
    "\n",
    "#         columns = [f'{catg_col}_{col}' for col in mapper[catg_col].classes_]\n",
    "#         if result.shape[1] == 1:\n",
    "#             columns = columns[:1]\n",
    "#         tmp.append(pd.DataFrame(data=result, columns=columns))\n",
    "#     tmp = pd.concat(tmp, 1)\n",
    "#     for col in tmp:\n",
    "#         catg_part[col] = tmp[col]\n",
    "#     pass\n",
    "\n",
    "# def do_woe_encoding(catg_ftrs, catg_part, status, data, is_train):\n",
    "#     pass\n",
    "\n",
    "# def do_target_encoding(catg_ftrs, catg_part, status, data, is_train):\n",
    "#     pass\n",
    "\n",
    "# def do_norm(num_features, status, data, is_train):\n",
    "#     num_part = data[num_features].copy()\n",
    "#     if is_train:\n",
    "#         scaler = StandardScaler()\n",
    "#         status['scaler'] = scaler\n",
    "#         num_part = pd.DataFrame(data=scaler.fit_transform(num_part), columns=num_part.columns)\n",
    "#     else:\n",
    "#         scaler = status['scaler']\n",
    "#         num_part = pd.DataFrame(data=scaler.transform(num_part), columns=num_part.columns)\n",
    "#     return num_part\n",
    "#     pass\n",
    "\n",
    "# def do_nth_order_polynominal(num_features, data):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_dist(y_pred):\n",
    "    y_pred = pd.Series(y_pred.ravel())\n",
    "    print( y_pred.describe() )\n",
    "    print( y_pred.mean(), y_pred.std() )\n",
    "    sns.lineplot(range(len(y_pred)), sorted(y_pred.ravel()))\n",
    "    plt.show()\n",
    "\n",
    "    sns.boxplot(y_pred.ravel(), orient='v')\n",
    "    plt.show()\n",
    "\n",
    "    sns.distplot(y_pred.ravel())\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def f_beta_scann(y_true, y_pred, beta=0.5):\n",
    "    y_pred = pd.Series(y_pred.ravel())\n",
    "    # 切割100等分, 尋找最佳 f beta score\n",
    "    bins = np.linspace(y_pred.min(), y_pred.max(), 100)\n",
    "    # 找出F beta score最高的點\n",
    "    result = np.array([precision_recall_fscore_support(y_true=y_true, y_pred=y_pred > thres, beta=beta)[2][1]\n",
    "                       for thres in bins])\n",
    "    best_idx = result.argmax()\n",
    "    return bins[best_idx], result[best_idx]\n",
    "\n",
    "\n",
    "def analyze(y_true, y_pred, beta=1):\n",
    "    thres, f_beta = f_beta_scann(y_true, y_pred, beta=beta)\n",
    "    acc = accuracy_score(y_true, y_pred.ravel() > thres)\n",
    "    print(f'thres: {thres:.4f}, f_beta score: {f_beta:.4f}')\n",
    "    print(f'accuracy@{thres:.4f}: {acc:.2f}\\n')\n",
    "\n",
    "    print(f'threshold@0.5, accuracy: {accuracy_score(y_true, y_pred.ravel() > 0.5):.4f}')\n",
    "    print(confusion_matrix(y_true, y_pred.ravel() > 0.5), '\\n')\n",
    "\n",
    "    print(f'threshold@{thres:.4f}, accuracy: {accuracy_score(y_true, y_pred.ravel() > thres):.4f}')\n",
    "    print(confusion_matrix(y_true, y_pred.ravel() > thres))\n",
    "\n",
    "    print(classification_report(y_true, y_pred.ravel() > thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>distress_num</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>...</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "      <th>distress_catg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.56657</td>\n",
       "      <td>1.1131</td>\n",
       "      <td>-0.015229</td>\n",
       "      <td>0.85888</td>\n",
       "      <td>0.80974</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>0.091033</td>\n",
       "      <td>0.67546</td>\n",
       "      <td>...</td>\n",
       "      <td>39.8</td>\n",
       "      <td>38.377</td>\n",
       "      <td>17.167</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.32539</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2.23200</td>\n",
       "      <td>2.2263</td>\n",
       "      <td>0.325880</td>\n",
       "      <td>0.40651</td>\n",
       "      <td>0.90804</td>\n",
       "      <td>0.455340</td>\n",
       "      <td>0.493550</td>\n",
       "      <td>1.65280</td>\n",
       "      <td>...</td>\n",
       "      <td>227.5</td>\n",
       "      <td>214.500</td>\n",
       "      <td>21.000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>29</td>\n",
       "      <td>2.65980</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1.27700</td>\n",
       "      <td>3.1096</td>\n",
       "      <td>0.133630</td>\n",
       "      <td>0.21635</td>\n",
       "      <td>0.70654</td>\n",
       "      <td>0.173030</td>\n",
       "      <td>0.446080</td>\n",
       "      <td>1.25870</td>\n",
       "      <td>...</td>\n",
       "      <td>227.5</td>\n",
       "      <td>214.500</td>\n",
       "      <td>21.000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>12</td>\n",
       "      <td>1.09640</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1.63780</td>\n",
       "      <td>1.2121</td>\n",
       "      <td>0.084192</td>\n",
       "      <td>0.70161</td>\n",
       "      <td>0.33803</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.144520</td>\n",
       "      <td>0.93530</td>\n",
       "      <td>...</td>\n",
       "      <td>227.5</td>\n",
       "      <td>214.500</td>\n",
       "      <td>21.000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>23</td>\n",
       "      <td>1.53660</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.24963</td>\n",
       "      <td>1.0103</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>0.86908</td>\n",
       "      <td>1.13010</td>\n",
       "      <td>0.060494</td>\n",
       "      <td>0.007169</td>\n",
       "      <td>0.81619</td>\n",
       "      <td>...</td>\n",
       "      <td>227.5</td>\n",
       "      <td>214.500</td>\n",
       "      <td>21.000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.11538</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company  Time  distress_num      x1        x2       x3       x4        x5  \\\n",
       "3         1     4      -0.56657  1.1131 -0.015229  0.85888  0.80974  0.076037   \n",
       "17        2    14       2.23200  2.2263  0.325880  0.40651  0.90804  0.455340   \n",
       "32        4    14       1.27700  3.1096  0.133630  0.21635  0.70654  0.173030   \n",
       "46        5    14       1.63780  1.2121  0.084192  0.70161  0.33803  0.130500   \n",
       "60        6    14       0.24963  1.0103  0.005959  0.86908  1.13010  0.060494   \n",
       "\n",
       "          x6       x7      ...          x75      x76     x77   x78  x79  x80  \\\n",
       "3   0.091033  0.67546      ...         39.8   38.377  17.167  16.0  5.6   22   \n",
       "17  0.493550  1.65280      ...        227.5  214.500  21.000  20.5  8.6   29   \n",
       "32  0.446080  1.25870      ...        227.5  214.500  21.000  20.5  8.6   12   \n",
       "46  0.144520  0.93530      ...        227.5  214.500  21.000  20.5  8.6   23   \n",
       "60  0.007169  0.81619      ...        227.5  214.500  21.000  20.5  8.6    9   \n",
       "\n",
       "        x81  x82  x83  distress_catg  \n",
       "3  -0.32539   33   52              1  \n",
       "17  2.65980   20   40              0  \n",
       "32  1.09640   41   57              0  \n",
       "46  1.53660   25   50              0  \n",
       "60  0.11538   23   54              0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_vl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-ad7a235f4ef0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rfm_mapper'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Company'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_vl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompany\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3564\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3565\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3566\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3568\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reindex_axis'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3688\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[1;32m-> 3689\u001b[1;33m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[0;32m   3690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   3499\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3500\u001b[0m             frame = frame._reindex_index(index, method, copy, level,\n\u001b[1;32m-> 3501\u001b[1;33m                                          fill_value, limit, tolerance)\n\u001b[0m\u001b[0;32m   3502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3503\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   3510\u001b[0m         return self._reindex_with_indexers({0: [new_index, indexer]},\n\u001b[0;32m   3511\u001b[0m                                            \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3512\u001b[1;33m                                            allow_dups=False)\n\u001b[0m\u001b[0;32m   3513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3514\u001b[0m     def _reindex_columns(self, new_columns, method, copy, level,\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   3808\u001b[0m                                                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3809\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3810\u001b[1;33m                                                 copy=copy)\n\u001b[0m\u001b[0;32m   3811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3812\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   4412\u001b[0m         \u001b[1;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4414\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   3574\u001b[0m         \u001b[1;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3575\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3576\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3578\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(data=status['rfm_mapper'])\\\n",
    "  .set_index('Company')\\\n",
    "  .reindex(raw_vl.Company.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1538622762380,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "udNVad7usaNe",
    "outputId": "22eba0e1-e10a-4822-d26a-af193fdf0362",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Comnapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Comnapy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-dd6b9a3b1e40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Trnasform raw data to foramt model recognized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvl_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvl_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_vl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtr_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvl_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-e6f359b23935>\u001b[0m in \u001b[0;36mfeature_engineering\u001b[1;34m(raw, is_train, status)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# RFM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mdo_rfm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcatg_ftrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatg_part\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;31m# -----------------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\notebook\\allianz\\insurance_use_case\\solution\\financial_distress_functions.py\u001b[0m in \u001b[0;36mdo_rfm\u001b[1;34m(catg_ftrs, catg_part, status, data, is_train)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mrfm_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rfm_mapper'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrfm_mapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Comnapy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompany\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mcatg_part\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rfm_all_mean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rfm_all_mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   3907\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3908\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3909\u001b[1;33m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3910\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3911\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\anaconda3-5.2.0\\envs\\py3_6\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Comnapy'"
     ]
    }
   ],
   "source": [
    "# Trnasform raw data to foramt model recognized\n",
    "tr_x, tr_y, status = feature_engineering(raw, is_train=True)\n",
    "vl_x, vl_y, _ = feature_engineering(raw_vl, is_train=False, status=status)\n",
    "\n",
    "print( tr_x.shape, vl_x.shape )\n",
    "vl_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_y.value_counts() / 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52CvQZa1t2A7"
   },
   "source": [
    "## Model on Base Featue Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1575
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4037,
     "status": "ok",
     "timestamp": 1538621868067,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "SMJbH52ot1aD",
    "outputId": "70f5e5a7-4dc3-4269-f928-8c97c08f1598",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim):\n",
    "    model = Sequential()\n",
    "    # kernel_regularizer=regularizers.l2(0.005)\n",
    "    model.add(Dense(64, activation = 'selu', input_dim = input_dim))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(32, activation = 'selu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(16, activation = 'selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "from keras import callbacks\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = get_model(input_dim=tr_x.shape[1])\n",
    "hist = model.fit(tr_x, tr_y, \n",
    "                 validation_data=(vl_x, vl_y), \n",
    "                 batch_size=100,\n",
    "                 epochs=20,\n",
    "                 class_weight={0: 1, 1:204}) # class_weight={0: 1, 1:204}\n",
    "\n",
    "plot_result(hist)\n",
    "y_pred = model.predict(vl_x)\n",
    "draw_roc_curve(vl_y, y_pred)\n",
    "\n",
    "pred_dist(y_pred)\n",
    "analyze(vl_y, y_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(vl_x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_dist(y_pred):\n",
    "    y_pred = pd.Series(y_pred.ravel())\n",
    "    print( y_pred.describe() )\n",
    "    print( y_pred.mean(), y_pred.std() )\n",
    "    sns.lineplot(range(len(y_pred)), sorted(y_pred.ravel()))\n",
    "    plt.show()\n",
    "\n",
    "    sns.boxplot(y_pred.ravel(), orient='v')\n",
    "    plt.show()\n",
    "\n",
    "    sns.distplot(y_pred.ravel())\n",
    "    plt.show()\n",
    "    \n",
    "pred_dist(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出最佳閥值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 依照所有的閥值(切割100等分)算出F score, 找出分數最高的閥值\n",
    "def f_beta_scann(y_true, y_pred, beta=0.5):\n",
    "    y_pred = pd.Series(y_pred.ravel())\n",
    "    # 切割100等分, 尋找最佳 f beta score\n",
    "    bins = np.linspace(y_pred.min(), y_pred.max(), 100)\n",
    "    # 找出F beta score最高的點\n",
    "    result = np.array([precision_recall_fscore_support(y_true=y_true, y_pred=y_pred > thres, beta=beta)[2][1] \n",
    "                       for thres in bins])\n",
    "    best_idx = result.argmax()\n",
    "    return bins[best_idx], result[best_idx]\n",
    "\n",
    "def analyze(y_true, y_pred, beta=1):\n",
    "    thres, f_beta = f_beta_scann(y_true, y_pred, beta=beta)\n",
    "    acc = accuracy_score(y_true, y_pred.ravel() > thres)\n",
    "    print(f'thres: {thres:.4f}, f_beta score: {f_beta:.4f}')\n",
    "    print(f'accuracy@{thres:.4f}: {acc:.2f}\\n')\n",
    "\n",
    "    print(f'threshold@0.5, accuracy: {accuracy_score(y_true, y_pred.ravel() > 0.5):.4f}')\n",
    "    print(confusion_matrix(y_true, y_pred.ravel() > 0.5), '\\n')\n",
    "\n",
    "    print(f'threshold@{thres:.4f}, accuracy: {accuracy_score(y_true, y_pred.ravel() > thres):.4f}')\n",
    "    print(confusion_matrix(y_true, y_pred.ravel() > thres))\n",
    "    \n",
    "    print(classification_report(y_true, y_pred.ravel() > thres))\n",
    "\n",
    "# analyze(vl_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9MWinD-e6SX"
   },
   "source": [
    "## Bining Numeric Feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1538632948251,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "KEZCNmIMqlor",
    "outputId": "e3f26c9d-4262-4591-f24a-84e80ec60012"
   },
   "outputs": [],
   "source": [
    "def do_binning(catg_ftrs, status, data, is_train):\n",
    "    def quartile_binning(x):\n",
    "        bins = np.percentile(x, range(0, 100, 25))[1:].tolist()\n",
    "        iqr_x_150 = (bins[-1] - bins[0]) * 1.5\n",
    "        bins = [bins[0] - iqr_x_150] + bins + [bins[-1] + iqr_x_150]\n",
    "        result = pd.Series(np.digitize(x, bins)).map(pd.Series([0, 1, 2, 3, 4, 0])).values\n",
    "        return result, bins\n",
    "\n",
    "    for col in [f'x{i}' for i in range(1, 84) if i != 80]:\n",
    "        binned_name = f'binn_{col}'\n",
    "        if is_train:\n",
    "            result, bins = quartile_binning(data[col])\n",
    "            status['binn_mapper'][binned_name] = bins\n",
    "            data[binned_name] = result\n",
    "        else:\n",
    "            bins = status['binn_mapper'][binned_name]\n",
    "            data[binned_name] = pd.Series(np.digitize(data[col], bins))\\\n",
    "                                  .map(pd.Series([0, 1, 2, 3, 4, 0])).values\n",
    "\n",
    "        catg_ftrs.append(binned_name)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trnasform raw data to foramt model recognized\n",
    "tr_x, tr_y, status = feature_engineering(raw, is_train=True)\n",
    "vl_x, vl_y, _ = feature_engineering(raw_vl, is_train=False, status=status)\n",
    "\n",
    "print( tr_x.shape, vl_x.shape )\n",
    "tr_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (Binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim, emb_info, data):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    emb_inputs = [Input(shape=(1,)) for col in emb_info]\n",
    "    all_inputs = [inputs] + emb_inputs\n",
    "\n",
    "    embeddings = [Flatten(name=name)(Embedding(emb_info[name], 6, input_length=1)(emb))\n",
    "                  for name, emb in zip(emb_info.keys(), emb_inputs)]\n",
    "\n",
    "    concat = Concatenate(axis=1)([inputs] + embeddings)\n",
    "    nets = Dense(units=128, activation='selu')(concat)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=64, activation='selu')(nets)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=32, activation='selu')(nets)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=1, activation='linear')(nets)\n",
    "\n",
    "    model = Model(inputs=all_inputs, outputs=nets)\n",
    "    # model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "emb_info = {'Company': 422, 'x80': 37}\n",
    "emb_info.update(dict((f'binn_x{i}', len(tr_x[f'binn_x{i}'].unique())) for i in range(1, 84) if i != 80))\n",
    "\n",
    "model = get_model(len(num_features), emb_info, data=tr_x)\n",
    "emb_features = list(emb_info.keys())\n",
    "hist = model.fit([tr_x.drop(emb_features, 1)] + \n",
    "                 [tr_x[col][:, None] for col in tr_x[emb_features]],\n",
    "                 tr_y, \n",
    "                 validation_data=([vl_x.drop(emb_features, 1)] + \n",
    "                                  [vl_x[col][:, None] for col in vl_x[emb_features]], \n",
    "                                  vl_y), \n",
    "                 batch_size=100, \n",
    "                 epochs=20)\n",
    "\n",
    "plot_result(hist)\n",
    "# draw_roc_curve(vl_y, model.predict(vl_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EtiRvZDGVfV"
   },
   "source": [
    "## Add Weight of Evidence Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1538629657376,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "L_YwlDOpGVml",
    "outputId": "abfe5e13-576a-4d23-acc6-9cc8f4db9c78"
   },
   "outputs": [],
   "source": [
    "def do_woe_encoding(catg_ftrs, catg_part, status, data, is_train):\n",
    "\n",
    "    def woe_encode(x, label, data):\n",
    "        \"\"\"Calculate the Weight of Evidence of given categorical feature and label\n",
    "\n",
    "        :param x: Given feature name\n",
    "        :param label: Label name\n",
    "        :param data:\n",
    "        :return: WOE encoded dictionary\n",
    "        \"\"\"\n",
    "        total_vc = data[label].value_counts().sort_index()\n",
    "\n",
    "        def woe(pipe, total_vc):\n",
    "            # Count by label in this group\n",
    "            group_vc = pipe[label].value_counts().sort_index()\n",
    "\n",
    "            # Some class in the feature is missing, fill zero to missing class\n",
    "            if len(group_vc) < len(total_vc):\n",
    "                for key in total_vc.index:\n",
    "                    if key not in group_vc:\n",
    "                        group_vc[key] = 0.\n",
    "                group_vc = group_vc.sort_index()\n",
    "\n",
    "            # WOE formula\n",
    "            r = ((group_vc + 0.5) / total_vc).values\n",
    "\n",
    "            # Odd ratio => 1 to 0, you can define meaning of each class\n",
    "            return np.log(r[1] / r[0])\n",
    "\n",
    "        return data.groupby(x).apply(lambda pipe: woe(pipe, total_vc))\n",
    "\n",
    "    for catg_col in catg_ftrs:\n",
    "        if is_train:\n",
    "            kv = woe_encode(catg_col, 'Exited', data)\n",
    "            status['woe_mapper'][catg_col] = kv.to_dict()\n",
    "        else:\n",
    "            kv = pd.Series(status['woe_mapper'][catg_col])\n",
    "        catg_part[f'woe_{catg_col}'] = kv.reindex(data[catg_col]).values\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trnasform raw data to foramt model recognized\n",
    "tr_x, tr_y, status = feature_engineering(raw, is_train=True)\n",
    "vl_x, vl_y, _ = feature_engineering(raw_vl, is_train=False, status=status)\n",
    "\n",
    "print( tr_x.shape, vl_x.shape )\n",
    "tr_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xp-VkesMgDVz"
   },
   "source": [
    "## Model (WOE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1609
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4738,
     "status": "ok",
     "timestamp": 1538629717958,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "_1oC02RWeZoH",
    "outputId": "2c19cff1-1626-4319-8904-bf0f5bf81d36",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim):\n",
    "    model = Sequential()\n",
    "    # kernel_regularizer=regularizers.l2(0.005)\n",
    "    model.add(Dense(units = 20, activation = 'relu', kernel_initializer='uniform', input_dim = input_dim))\n",
    "    model.add(Dense(units = 20, activation = 'relu', kernel_initializer='uniform'))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer='uniform'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = get_model(input_dim=tr_x.shape[1])\n",
    "hist = model.fit(tr_x, tr_y, validation_data=(vl_x, vl_y), batch_size=100, epochs=30)\n",
    "plot_result(hist)\n",
    "draw_roc_curve(vl_y, model.predict(vl_x))\n",
    "\n",
    "y_pred = model.predict(vl_x)\n",
    "pred_dist(y_pred)\n",
    "analyze(vl_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Encoding, Target Encoding\n",
    "\n",
    "* Frequency encoding\n",
    "* Mean encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_target_encoding(catg_ftrs, catg_part, status, data, is_train):\n",
    "    for catg_col in catg_ftrs:\n",
    "        if is_train:\n",
    "            freq_proportion = data[catg_col].value_counts() / len(data)\n",
    "            catg_part[f'freq_{catg_col}'] = freq_proportion.reindex(data[catg_col]).values\n",
    "            target_mean = data.groupby(catg_col).Exited.mean()\n",
    "            catg_part[f'mean_{catg_col}'] = target_mean.reindex(data[catg_col]).values\n",
    "\n",
    "            status['freq_mapper'][catg_col] = freq_proportion.to_dict()\n",
    "            status['mean_mapper'][catg_col] = target_mean.to_dict()\n",
    "        else:\n",
    "            catg_part[f'freq_{catg_col}'] = pd.Series(status['freq_mapper'][catg_col]).reindex(data[catg_col]).values\n",
    "            catg_part[f'mean_{catg_col}'] = pd.Series(status['mean_mapper'][catg_col]).reindex(data[catg_col]).values\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trnasform raw data to foramt model recognized\n",
    "tr_x, tr_y, status = feature_engineering(raw, is_train=True)\n",
    "vl_x, vl_y, _ = feature_engineering(raw_vl, is_train=False, status=status)\n",
    "\n",
    "print( tr_x.shape, vl_x.shape )\n",
    "print(tr_x.columns.values)\n",
    "tr_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (WOE + Binning + Freqency Encoding + Target Mean Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim, emb_info, data):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    emb_inputs = [Input(shape=(1,)) for col in emb_info]\n",
    "    all_inputs = [inputs] + emb_inputs\n",
    "\n",
    "    embeddings = [Flatten(name=name)(Embedding(emb_info[name], 6, input_length=1)(emb))\n",
    "                  for name, emb in zip(emb_info.keys(), emb_inputs)]\n",
    "\n",
    "    concat = Concatenate(axis=1)([inputs] + embeddings)\n",
    "    nets = Dense(units=256, activation='selu')(concat)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=128, activation='selu')(nets)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=64, activation='selu')(nets)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=1, activation='linear')(nets)\n",
    "\n",
    "    model = Model(inputs=all_inputs, outputs=nets)\n",
    "    # model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "emb_info = {'Company': 422, 'x80': 37}\n",
    "# emb_info.update(dict((f'binn_x{i}', len(tr_x[f'binn_x{i}'].unique())) for i in range(1, 84) if i != 80))\n",
    "emb_features = list(emb_info.keys())\n",
    "\n",
    "model = get_model(tr_x.drop(emb_features, 1).shape[1], emb_info, data=tr_x)\n",
    "hist = model.fit([tr_x.drop(emb_features, 1)] + \n",
    "                 [tr_x[col][:, None] for col in tr_x[emb_features]],\n",
    "                 tr_y, \n",
    "                 validation_data=([vl_x.drop(emb_features, 1)] + \n",
    "                                  [vl_x[col][:, None] for col in vl_x[emb_features]], \n",
    "                                  vl_y), \n",
    "                 batch_size=100, \n",
    "                 epochs=20)\n",
    "\n",
    "plot_result(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5crE3xFBn91"
   },
   "source": [
    "## Add Polynomial Featue Engineering\n",
    "\n",
    "* Add quradratic, cube term base on numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1538626022744,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "0m8uAkjbuBa7",
    "outputId": "c318f7e6-0352-4a2a-b340-41b3b38e568a"
   },
   "outputs": [],
   "source": [
    "# def do_nth_order_polynominal(num_features, data):\n",
    "#     for num_col in num_features:\n",
    "#         data[f'{num_col}_degree_2'] = data[num_col] ** 2\n",
    "#         data[f'{num_col}_degree_3'] = data[num_col] ** 3\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trnasform raw data to foramt model recognized\n",
    "tr_x, tr_y, status = feature_engineering(raw, is_train=True)\n",
    "vl_x, vl_y, _ = feature_engineering(raw_vl, is_train=False, status=status)\n",
    "\n",
    "print( tr_x.shape, vl_x.shape )\n",
    "tr_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wfc1V2cYFz50"
   },
   "source": [
    "## Model (WOE + Binning + Freqency Encoding + Target Mean Encoding + Polynominal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1609
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4788,
     "status": "ok",
     "timestamp": 1538626029956,
     "user": {
      "displayName": "Gary Chen",
      "photoUrl": "",
      "userId": "10783188122132859162"
     },
     "user_tz": -480
    },
    "id": "Dl32_fhCFz-_",
    "outputId": "4cc0a562-f5c6-44fd-ce29-1c52974296f2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim, emb_info, data):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    emb_inputs = [Input(shape=(1,)) for col in emb_info]\n",
    "    all_inputs = [inputs] + emb_inputs\n",
    "\n",
    "    embeddings = [Flatten(name=name)(Embedding(emb_info[name], 6, input_length=1)(emb))\n",
    "                  for name, emb in zip(emb_info.keys(), emb_inputs)]\n",
    "\n",
    "    concat = Concatenate(axis=1)([inputs] + embeddings)\n",
    "    nets = Dense(units=256, activation='selu')(concat)\n",
    "    nets = Dropout(.6)(nets)\n",
    "    nets = Dense(units=128, activation='selu')(nets)\n",
    "    nets = Dropout(.6)(nets)\n",
    "    nets = Dense(units=64, activation='selu')(nets)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=1, activation='sigmoid')(nets)\n",
    "\n",
    "    model = Model(inputs=all_inputs, outputs=nets)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "emb_info = {'Company': 422, 'x80': 37}\n",
    "# emb_info.update(dict((f'binn_x{i}', len(tr_x[f'binn_x{i}'].unique())) for i in range(1, 84) if i != 80))\n",
    "emb_features = list(emb_info.keys())\n",
    "\n",
    "model = get_model(tr_x.drop(emb_features, 1).shape[1], emb_info, data=tr_x)\n",
    "hist = model.fit([tr_x.drop(emb_features, 1)] + \n",
    "                 [tr_x[col][:, None] for col in tr_x[emb_features]],\n",
    "                 tr_y, \n",
    "                 validation_data=([vl_x.drop(emb_features, 1)] + \n",
    "                                  [vl_x[col][:, None] for col in vl_x[emb_features]], \n",
    "                                  vl_y), \n",
    "                 batch_size=1000, \n",
    "                 epochs=30)\n",
    "\n",
    "plot_result(hist)\n",
    "draw_roc_curve(vl_y, model.predict([vl_x.drop(emb_features, 1)] + \n",
    "                                   [vl_x[col][:, None] for col in vl_x[emb_features]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依照所有的閥值(切割100等分)算出F score, 找出分數最高的閥值\n",
    "def f_beta_scann(y_true, y_pred, beta=0.5):\n",
    "    y_pred = pd.Series(y_pred.ravel())\n",
    "    # 切割100等分, 尋找最佳 f beta score\n",
    "    bins = np.linspace(y_pred.min(), y_pred.max(), 100)\n",
    "    # 找出F beta score最高的點\n",
    "    result = np.array([precision_recall_fscore_support(y_true=y_true, y_pred=y_pred > thres, beta=beta)[2][1] \n",
    "                       for thres in bins])\n",
    "    best_idx = result.argmax()\n",
    "    return bins[best_idx], result[best_idx]\n",
    "\n",
    "def analyze(y_true, y_pred, beta=0.5):\n",
    "    thres, f_beta = f_beta_scann(y_true, y_pred, beta=beta)\n",
    "    acc = accuracy_score(y_true, y_pred.ravel() > thres)\n",
    "    print(f'thres: {thres:.4f}, f_beta score: {f_beta:.4f}')\n",
    "    print(f'accuracy@{thres:.4f}: {acc:.2f}\\n')\n",
    "\n",
    "    print(f'threshold@0.5, accuracy: {accuracy_score(y_true, y_pred.ravel() > 0.5):.4f}')\n",
    "    print(confusion_matrix(y_true, y_pred.ravel() > 0.5), '\\n')\n",
    "\n",
    "    print(f'threshold@{thres:.4f}, accuracy: {accuracy_score(y_true, y_pred.ravel() > thres):.4f}')\n",
    "    print(confusion_matrix(y_true, y_pred.ravel() > thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([vl_x.drop(emb_features, 1)] + \n",
    "                       [vl_x[col][:, None] for col in vl_x[emb_features]])\n",
    "analyze(vl_y, y_pred)\n",
    "draw_roc_curve(vl_y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=64)\n",
    "tr_x_pca = pca.fit_transform(tr_x)\n",
    "vl_x_pca = pca.transform(vl_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x_pca.shape, vl_x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim, emb_info, data):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    emb_inputs = [Input(shape=(1,)) for col in emb_info]\n",
    "    all_inputs = [inputs] + emb_inputs\n",
    "\n",
    "    embeddings = [Flatten(name=name)(Embedding(emb_info[name], 6, input_length=1)(emb))\n",
    "                  for name, emb in zip(emb_info.keys(), emb_inputs)]\n",
    "\n",
    "    concat = Concatenate(axis=1)([inputs] + embeddings)\n",
    "    nets = Dense(units=256, activation='selu')(concat)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=128, activation='selu')(nets)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=64, activation='selu')(nets)\n",
    "    nets = Dropout(.5)(nets)\n",
    "    nets = Dense(units=1, activation='linear')(nets)\n",
    "\n",
    "    model = Model(inputs=all_inputs, outputs=nets)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "emb_info = {'Company': 422, 'x80': 37}\n",
    "# emb_info.update(dict((f'binn_x{i}', len(tr_x[f'binn_x{i}'].unique())) for i in range(1, 84) if i != 80))\n",
    "emb_features = list(emb_info.keys())\n",
    "\n",
    "model = get_model(tr_x.drop(emb_features, 1).shape[1], emb_info, data=tr_x)\n",
    "hist = model.fit([tr_x.drop(emb_features, 1)] + \n",
    "                 [tr_x[col][:, None] for col in tr_x[emb_features]],\n",
    "                 tr_y, \n",
    "                 validation_data=([vl_x.drop(emb_features, 1)] + \n",
    "                                  [vl_x[col][:, None] for col in vl_x[emb_features]], \n",
    "                                  vl_y), \n",
    "                 batch_size=1000, \n",
    "                 epochs=60)\n",
    "\n",
    "plot_result(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (AutoEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trnasform raw data to foramt model recognized\n",
    "tr_x, tr_y, status = feature_engineering(raw, is_train=True)\n",
    "vl_x, vl_y, _ = feature_engineering(raw_vl, is_train=False, status=status)\n",
    "\n",
    "print( tr_x.shape, vl_x.shape )\n",
    "tr_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inputs_dim = tr_x.shape[1]\n",
    "\n",
    "inputs = Input(shape=(inputs_dim, ))\n",
    "# Encoder\n",
    "encoded = Dense(inputs_dim, activation='selu')(inputs)\n",
    "encoded = Dense(128, activation='selu')(encoded)\n",
    "encoded = Dense(64, activation='selu')(encoded)\n",
    "encoded = Dense(64, activation='selu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(64, activation='selu')(encoded)\n",
    "decoded = Dense(64, activation='selu')(decoded)\n",
    "decoded = Dense(128, activation='selu')(decoded)\n",
    "decoded = Dense(inputs_dim, activation='linear')(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(inputs, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "# Adam Optimizer + Mean square error loss\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "hist = autoencoder.fit(\n",
    "    tr_x, tr_x, \n",
    "    epochs=100, \n",
    "    batch_size=200, \n",
    "    shuffle=True, \n",
    "    validation_data=(vl_x, vl_x))\n",
    "\n",
    "def plot_ae(hist):\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    plt.plot(hist.history['loss'], label='tr_loss')\n",
    "    plt.plot(hist.history['val_loss'], label='vl_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "plot_ae(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr_x_ae = encoder.predict(tr_x)\n",
    "vl_x_ae = encoder.predict(vl_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x_ae.shape, vl_x_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim):\n",
    "    model = Sequential()\n",
    "    # kernel_regularizer=regularizers.l2(0.005)\n",
    "    model.add(Dense(units = 128, activation = 'relu', kernel_initializer='uniform', input_dim = input_dim))\n",
    "    model.add(Dense(units = 128, activation = 'relu', kernel_initializer='uniform'))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer='uniform'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = get_model(input_dim=tr_x_ae.shape[1])\n",
    "hist = model.fit(tr_x_ae, tr_y, validation_data=(vl_x_ae, vl_y), batch_size=100, epochs=30)\n",
    "\n",
    "plot_result(hist)\n",
    "draw_roc_curve(vl_y, model.predict(vl_x_ae))\n",
    "\n",
    "y_pred = model.predict(vl_x_ae)\n",
    "pred_dist(y_pred)\n",
    "analyze(vl_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model_finance_customer_churn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
